{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GummyBear-w/aop113b/blob/main/HW02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW02 Web Crawler"
      ],
      "metadata": {
        "id": "eo72fZ0YlURV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "完整的程式碼、csv檔及更多介紹可以在我的[Github](https://github.com/GummyBear-w/Ebook_Price_Scraper)查看（搭配服用效果更佳）"
      ],
      "metadata": {
        "id": "ju80g9M5oksJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 題目"
      ],
      "metadata": {
        "id": "gUsBAopRJMJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kobo電子書價格追蹤**"
      ],
      "metadata": {
        "id": "pDHhflLyJRgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 摘要"
      ],
      "metadata": {
        "id": "hbqT3pl04Hl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "透過網路爬蟲技術每日自動蒐集Kobo電子書價格資料，並進行視覺化分析，建立一套價格波動追蹤系統。\n"
      ],
      "metadata": {
        "id": "eweMw-wh4TC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 引言"
      ],
      "metadata": {
        "id": "9nb1aHAM4XiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我本身有在Kobo平台上購買電子書的習慣，希望能夠透過爬蟲技術幫助自己更方便地追蹤感興趣的書籍價格，收集資料來了解價格波動趨勢、歷史低價、折扣週期，以便找到最優惠的購買價格。"
      ],
      "metadata": {
        "id": "0ZmT034r5F9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 方法"
      ],
      "metadata": {
        "id": "8YMFd39F4n4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 目標網站描述\n",
        "  - 目標網站：[Kobo.com台灣商店](https://www.kobo.com/tw)\n",
        "  \n",
        "  - 頁面結構：包含書籍名稱、圖片、價格等資訊。\n",
        "\n",
        "- 工具與技術\n",
        "  - 語言與函式庫：Python（Selenium、Plotly、Pandas、CSV）\n",
        "\n",
        "  - 自動化排程與部署：GitHub Actions、crontab 時間排程、Token 權限設定\n",
        "\n",
        "  - 資料儲存：CSV\n",
        "\n",
        "  - 視覺化頁面生成：Bootstrap + HTML + Plotly 圖表 iframe 內嵌"
      ],
      "metadata": {
        "id": "zkix6XqZ429E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 爬取資料程式碼\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "import csv\n",
        "import os\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "def random_sleep(a=1.5, b=3.0):\n",
        "    time.sleep(random.uniform(a, b))\n",
        "\n",
        "def get_all_book_links(driver, wait, base_url):\n",
        "    driver.get(base_url)\n",
        "    book_links = []\n",
        "    page_num = 1\n",
        "    max_pages = 10  # 最多處理 10 頁，以免自動排程執行後出現bug時不停訪問網站\n",
        "\n",
        "    current_url = driver.current_url\n",
        "    while page_num <= max_pages:\n",
        "        print(f\"正在處理第 {page_num} 頁...\")\n",
        "        random_sleep(2, 4)\n",
        "\n",
        "        books = driver.find_elements(By.CSS_SELECTOR, \"div.book-card h2 a.cdk-link\")\n",
        "        for book in books:\n",
        "            try:\n",
        "                href = book.get_attribute(\"href\")\n",
        "                if href and href not in book_links:\n",
        "                    book_links.append(href)\n",
        "            except StaleElementReferenceException:\n",
        "                continue\n",
        "        # 透過網址變動確認是否到達最末頁\n",
        "        try:\n",
        "            next_button = driver.find_element(By.CSS_SELECTOR, 'button.control-button[aria-label=\"next page\"]')\n",
        "            if next_button.get_attribute(\"aria-disabled\") == \"true\" or \"disabled\" in next_button.get_attribute(\"class\"):\n",
        "                print(\"✅ 已到最後一頁\")\n",
        "                break\n",
        "            else:\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
        "                random_sleep(0.8, 1.5)\n",
        "                driver.execute_script(\"arguments[0].click();\", next_button)\n",
        "                random_sleep(2, 4)\n",
        "\n",
        "                # 確認 URL 是否變動\n",
        "                new_url = driver.current_url\n",
        "                if new_url == current_url:\n",
        "                    print(\"✅ 網址沒有變化，應是最後一頁\")\n",
        "                    break\n",
        "                current_url = new_url\n",
        "\n",
        "                page_num += 1\n",
        "        except NoSuchElementException:\n",
        "            print(\"❌ 找不到下一頁按鈕，結束\")\n",
        "            break\n",
        "\n",
        "    return book_links\n",
        "\n",
        "# 抓取內頁詳細資訊，包括書名、價位、圖片、isbn碼\n",
        "def extract_book_info(driver, wait, url):\n",
        "    driver.get(url)\n",
        "    try:\n",
        "        title = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.item-info h1.title\"))).text\n",
        "    except:\n",
        "        title = \"無法取得書名\"\n",
        "\n",
        "    try:\n",
        "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.pricing-figures\")))\n",
        "        random_sleep(1, 2)\n",
        "        price_elem = driver.find_element(By.CSS_SELECTOR, \"div.pricing-figures span.price\")\n",
        "        price_text = driver.execute_script(\"return arguments[0].textContent;\", price_elem).strip()\n",
        "        price = price_text.replace(\"NT$\", \"\").replace(\",\", \"\").strip()\n",
        "    except:\n",
        "        price = \"無法取得價格\"\n",
        "\n",
        "    try:\n",
        "        isbn = \"無法取得\"\n",
        "        lis = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.bookitem-secondary-metadata li\")))\n",
        "        for li in lis:\n",
        "            if \"書籍ID：\" in li.text:\n",
        "                isbn = li.text.replace(\"書籍ID：\", \"\").strip()\n",
        "                break\n",
        "    except:\n",
        "        isbn = \"無法取得 ISBN\"\n",
        "\n",
        "    try:\n",
        "        image_url = wait.until(EC.presence_of_element_located(\n",
        "            (By.CSS_SELECTOR, \"div.item-image img.cover-image\"))).get_attribute(\"src\")\n",
        "    except:\n",
        "        image_url = \"無法取得圖片\"\n",
        "\n",
        "    return {\n",
        "        \"書名\": title,\n",
        "        \"價格\": price,\n",
        "        \"ISBN\": isbn,\n",
        "        \"封面照片\": image_url,\n",
        "        \"連結\": url\n",
        "    }\n",
        "\n",
        "# 主流程\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument(\"--window-size=1920,1080\")\n",
        "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
        "driver = webdriver.Chrome(options=options)\n",
        "wait = WebDriverWait(driver, 10)\n",
        "\n",
        "authors = {\n",
        "    \"卡繆\": \"https://www.kobo.com/tw/zh/search?query=%E5%8D%A1%E7%B9%86&ac=1&acp=%E5%8D%A1%E7%B9%86&ac.author=%E5%8D%A1%E7%B9%86&acpos=a2&uir=true&fclanguages=zh&fcsearchfield=author\",\n",
        "    \"簡媜\": \"https://www.kobo.com/tw/zh/search?query=%E7%B0%A1%E5%AA%9C&ac=1&ac.morein=true&ac.author=%E7%B0%A1%E5%AA%9C&fcsearchfield=author&fclanguages=zh\",\n",
        "    \"赫曼．赫塞\": \"https://www.kobo.com/tw/zh/search?query=%E8%B5%AB%E6%9B%BC%EF%BC%8E%E8%B5%AB%E5%A1%9E+&ac=1&ac.morein=true&ac.author=%E8%B5%AB%E6%9B%BC%EF%BC%8E%E8%B5%AB%E5%A1%9E+&fcsearchfield=author&fclanguages=zh\"\n",
        "}\n",
        "\n",
        "csv_file = \"book_prices.csv\"\n",
        "csv_headers = [\"日期\", \"作者\", \"書名\", \"價格\", \"ISBN\", \"封面照片\", \"連結\"]\n",
        "\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, mode='w', newline='', encoding='utf-8-sig') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=csv_headers)\n",
        "        writer.writeheader()\n",
        "\n",
        "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "for author, url in authors.items():\n",
        "    print(f\"\\n=== 處理作者：{author} ===\")\n",
        "    book_links = get_all_book_links(driver, wait, url)\n",
        "    print(f\"共取得 {len(book_links)} 筆連結\")\n",
        "\n",
        "    for idx, link in enumerate(book_links, 1):\n",
        "        print(f\"→ 第 {idx} 本書：{link}\")\n",
        "        info = extract_book_info(driver, wait, link)\n",
        "        info[\"日期\"] = today\n",
        "        info[\"作者\"] = author\n",
        "\n",
        "        with open(csv_file, mode='a', newline='', encoding='utf-8-sig') as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=csv_headers)\n",
        "            writer.writerow(info)\n",
        "\n",
        "print(\"\\n✅ 資料已儲存至 book_prices.csv\")\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "ziaWIQ0t8vKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結果\n"
      ],
      "metadata": {
        "id": "mHEo_iad7QMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 每日自動爬取資料\n",
        "  - 每日透過 GitHub Actions 自動執行爬蟲程式，長期累積以利後續追蹤變動趨勢\n",
        "- 資料存儲方式\n",
        "  - 將資料存儲為 CSV 格式，方便後續分析\n",
        "- 簡易的視覺化呈現\n",
        "  - 利用 Plotly 每日更新各書的價格折線圖（以ISBN區分）\n",
        "  - 利用 GitHub Pages 自動部署成[公開網頁](https://gummybear-w.github.io/Ebook_Price_Scraper/)"
      ],
      "metadata": {
        "id": "Fx3h33cU8n8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 展示資料程式碼\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# 讀取資料\n",
        "csv_file = \"book_prices.csv\"\n",
        "df = pd.read_csv(csv_file)\n",
        "df[\"日期\"] = pd.to_datetime(df[\"日期\"])\n",
        "df[\"價格\"] = pd.to_numeric(df[\"價格\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"價格\", \"ISBN\"])\n",
        "\n",
        "# 確保 docs 資料夾存在\n",
        "os.makedirs(\"docs\", exist_ok=True)\n",
        "\n",
        "# 各本書生成價格折線圖\n",
        "isbn_to_plot_path = {}\n",
        "for isbn, group in df.groupby(\"ISBN\"):\n",
        "    if group.shape[0] < 2:\n",
        "        continue  # 只有一天資料不用畫圖\n",
        "    fig = px.line(\n",
        "        group,\n",
        "        x=\"日期\",\n",
        "        y=\"價格\"\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        margin=dict(t=40),  # 避免圖表被擠到\n",
        "   )\n",
        "\n",
        "    fig.update_layout(xaxis_tickformat=\"%Y-%m-%d\")\n",
        "\n",
        "    fig.update_traces(hovertemplate=\"日期：%{x}<br>價格：NT$%{y}<extra></extra>\", mode=\"lines+markers\")\n",
        "\n",
        "    plot_path = f\"plot_{isbn}.html\"\n",
        "    fig.write_html(f\"docs/{plot_path}\", include_plotlyjs=\"cdn\", full_html=False)\n",
        "    isbn_to_plot_path[isbn] = plot_path\n",
        "\n",
        "# 得到最新日期以用於每本書最新價格\n",
        "latest_date = df[\"日期\"].max()\n",
        "latest_df = df[df[\"日期\"] == latest_date]\n",
        "\n",
        "# 各 ISBN 最低價格\n",
        "min_price = df.groupby(\"ISBN\")[\"價格\"].min()\n",
        "\n",
        "# 以作者分群\n",
        "authors = [\"全部作者\"] + sorted(df[\"作者\"].unique())\n",
        "\n",
        "# 生成 index.html\n",
        "with open(\"docs/index.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"zh\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>電子書價格追蹤</title>\n",
        "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        a.card-title-link {\n",
        "            text-decoration: none;\n",
        "            color: black;\n",
        "        }\n",
        "        a.card-title-link:hover {\n",
        "            color: #555;\n",
        "        }\n",
        "    </style>\n",
        "\n",
        "</head>\n",
        "<body class=\"bg-light\">\n",
        "<div class=\"container py-4\">\n",
        "    <h1 class=\"mb-4\">電子書價格追蹤</h1>\n",
        "    <div class=\"mb-4\">\n",
        "        <label for=\"authorSelect\" class=\"form-label\">下拉式選單 選擇作者：</label>\n",
        "        <select class=\"form-select\" id=\"authorSelect\" onchange=\"filterByAuthor()\">\n",
        "\"\"\")\n",
        "    for author in authors:\n",
        "        value = author if author != \"全部作者\" else \"all\"\n",
        "        f.write(f'<option value=\"{value}\">{author}</option>\\n')\n",
        "    f.write(\"\"\"\n",
        "        </select>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"mb-4\">\n",
        "        <label for=\"searchInput\" class=\"form-label\">搜尋書名：</label>\n",
        "        <input type=\"text\" class=\"form-control\" id=\"searchInput\" oninput=\"filterBooks()\" placeholder=\"輸入書名關鍵字\">\n",
        "    </div>\n",
        "\n",
        "    <div id=\"bookCards\">\n",
        "\"\"\")\n",
        "    for _, row in latest_df.iterrows():\n",
        "        isbn = row[\"ISBN\"]\n",
        "        image = row[\"封面照片\"]\n",
        "        title = row[\"書名\"]\n",
        "        price = row[\"價格\"]\n",
        "        link = row[\"連結\"]\n",
        "        author = row[\"作者\"]\n",
        "        min_p = min_price.get(isbn, price)\n",
        "        chart_html = f'<iframe src=\"{isbn_to_plot_path.get(isbn, \"\")}\" width=\"100%\" height=\"300\"></iframe>' if isbn in isbn_to_plot_path else '<p class=\"text-muted\">目前無歷史價格資料</p>'\n",
        "        f.write(f\"\"\"\n",
        "<div class=\"card mb-4\" data-author=\"{author}\">\n",
        "  <div class=\"row g-0\">\n",
        "    <div class=\"col-md-3 d-flex align-items-center justify-content-center\">\n",
        "      <img src=\"{image}\" class=\"img-fluid rounded-start\" alt=\"封面\" style=\"height: 200px; object-fit: contain;\">\n",
        "    </div>\n",
        "    <div class=\"col-md-9\">\n",
        "      <div class=\"card-body\">\n",
        "        <h5 class=\"card-title\"><a href=\"{link}\" target=\"_blank\" class=\"card-title-link\">{title}</a></h5>\n",
        "        <p class=\"card-text\">本日價格：NT${price}　歷史低價：NT${min_p}</p>\n",
        "        {chart_html}\n",
        "      </div>\n",
        "    </div>\n",
        "  </div>\n",
        "</div>\n",
        "\"\"\")\n",
        "    f.write(\"\"\"\n",
        "    </div>\n",
        "</div>\n",
        "<script>\n",
        "function filterBooks() {\n",
        "    const selectedAuthor = document.getElementById(\"authorSelect\").value;\n",
        "    const keyword = document.getElementById(\"searchInput\").value.toLowerCase();\n",
        "\n",
        "    document.querySelectorAll(\"#bookCards .card\").forEach(card => {\n",
        "        const author = card.dataset.author;\n",
        "        const title = card.querySelector(\".card-title\").innerText.toLowerCase();\n",
        "        const matchAuthor = (selectedAuthor === \"all\" || author === selectedAuthor);\n",
        "        const matchTitle = title.includes(keyword);\n",
        "        card.style.display = (matchAuthor && matchTitle) ? \"\" : \"none\";\n",
        "    });\n",
        "}\n",
        "document.getElementById(\"authorSelect\").addEventListener(\"change\", filterBooks);\n",
        "</script>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "jsLbLuSa8mnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 網頁呈現的效果如圖，利用***折線圖***可以輕鬆看出價格波動，也有簡單的篩選和搜尋功能。\n",
        "\n",
        "<img src=\"https://github.com/GummyBear-w/Ebook_Price_Scraper/raw/main/demo.gif\" width=\"85%\">\n",
        "\n"
      ],
      "metadata": {
        "id": "lchiRoJvsCuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 問題與挑戰"
      ],
      "metadata": {
        "id": "6yHFop_b73gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 技術挑戰  \n",
        "\n",
        "    **動態內容載入：**\n",
        "\n",
        "    Kobo 的書籍搜尋與詳細頁面內容多透過 JavaScript 動態產生，像是價格與封面圖片都在頁面載入後才被插入 DOM，無法使用 **requests** 等靜態爬蟲工具直接抓取，改為採用 **Selenium** 來模擬真實使用者行為，能正確載入並操作網頁內容，透過等待元素出現、模擬分頁點擊與延遲操作等方式，繞過限制並穩定取得所需資料。\n",
        "- 資料限制  \n",
        "    爬取的書本數量較少"
      ],
      "metadata": {
        "id": "D6roihku8PBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結論"
      ],
      "metadata": {
        "id": "VeQHgVuqqD3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 成功獲取感興趣的書籍價格資料，並自動化長期追蹤及視覺化呈現。\n",
        "- 未來可擴展至其他電子書平台，進行跨平台比較分析。"
      ],
      "metadata": {
        "id": "Baea2g7J9DAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 參考文獻"
      ],
      "metadata": {
        "id": "j5hI_9QW9dTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Python 進階爬蟲](https://hackmd.io/@AndyChiang/DynamicCrawler)\n",
        "* [動態網頁爬蟲-使用Selenium](https://hackmd.io/@aaronlife/python-topic-selenium)\n",
        "* [【資料分析】Python爬蟲入門實作（下）](https://medium.com/@kaojia/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-python%E7%88%AC%E8%9F%B2%E5%85%A5%E9%96%80%E5%AF%A6%E4%BD%9C-%E4%B8%8B-%E5%8B%95%E6%85%8B%E7%B6%B2%E9%A0%81%E7%88%AC%E8%9F%B2-%E5%8F%8D%E5%8F%8D%E7%88%AC%E8%9F%B2-json-%E6%A0%BC%E5%BC%8F-2170c88b0ec8)\n",
        "* [樂天 Kobo Taiwan](https://kobo.com/tw)"
      ],
      "metadata": {
        "id": "eLFvp2Fk9fSa"
      }
    }
  ]
}